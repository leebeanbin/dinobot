"""
Notion ë™ê¸°í™” ì„œë¹„ìŠ¤ ëª¨ë“ˆ
- í˜ì´ì§€ ì‚­ì œ ê°ì§€
- ìŠ¤ë ˆë“œ ë¹„í™œì„±í™”
- ì‹¤ì‹œê°„ ë™ê¸°í™”
"""

import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

from src.core.database import get_meetup_collection, mongodb_connection
from src.core.logger import get_logger
from src.core.exceptions import safe_execution
from src.core.config import settings

# notion_serviceëŠ” ServiceManagerë¥¼ í†µí•´ ì ‘ê·¼
# from .notion import notion_service
# discord_serviceëŠ” ServiceManagerë¥¼ í†µí•´ ì ‘ê·¼
# from .discord_service import discord_service

# Module logger
logger = get_logger("services.sync")


class SyncService:
    """
    Notion synchronization service responsible for maintaining data consistency
    between Notion pages and local MongoDB storage
    """

    def __init__(self):
        self.synchronization_interval_seconds = (
            600  # Sync every 10 minutes for reduced API calls
        )
        self.is_synchronization_running = False
        self.background_sync_task = None
        # Performance optimization cache
        self._notion_page_cache = {}  # Maps page_id -> last_modification_timestamp
        self._last_successful_sync_timestamp = None

    @safe_execution("start_sync_monitor")
    async def start_continuous_synchronization_monitor(self):
        """Start continuous synchronization monitoring service"""
        if self.is_synchronization_running:
            logger.warning("âš ï¸ Synchronization monitoring service is already running")
            return

        self.is_synchronization_running = True
        # Starting Notion synchronization monitoring service (ë¡œê·¸ ì œê±°)

        # Execute synchronization in background task
        self.background_sync_task = asyncio.create_task(
            self._execute_continuous_sync_loop()
        )

    @safe_execution("stop_sync_monitor")
    async def stop_synchronization_monitor(self):
        """Stop synchronization monitoring service gracefully"""
        if not self.is_synchronization_running:
            return

        self.is_synchronization_running = False
        if self.background_sync_task:
            self.background_sync_task.cancel()
            try:
                await self.background_sync_task
            except asyncio.CancelledError:
                pass

        logger.info("ğŸ›‘ Notion synchronization monitoring service stopped")

    @safe_execution("clean_deleted_pages")
    async def clean_invalid_database_entries(self):
        """Clean up invalid database entries with empty or malformed page IDs"""
        try:
            collection = get_meetup_collection("notion_pages")

            # ë¹ˆ í˜ì´ì§€ IDë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ í˜ì´ì§€ IDë¥¼ ê°€ì§„ í•­ëª© ì°¾ê¸°
            invalid_entries = await collection.find(
                {
                    "$or": [
                        {"page_id": {"$exists": False}},
                        {"page_id": ""},
                        {"page_id": None},
                        {"page_id": {"$regex": "^\\s*$"}},  # ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°
                    ]
                }
            ).to_list(None)

            if invalid_entries:
                # ì˜ëª»ëœ í•­ëª©ë“¤ ì‚­ì œ
                result = await collection.delete_many(
                    {
                        "$or": [
                            {"page_id": {"$exists": False}},
                            {"page_id": ""},
                            {"page_id": None},
                            {"page_id": {"$regex": "^\\s*$"}},
                        ]
                    }
                )
                logger.info(
                    f"ğŸ§¹ ì˜ëª»ëœ ë°ì´í„°ë² ì´ìŠ¤ í•­ëª© {result.deleted_count}ê°œ ì •ë¦¬ ì™„ë£Œ"
                )
                return result.deleted_count
            else:
                logger.debug("âœ… ì •ë¦¬í•  ì˜ëª»ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
                return 0

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0

    async def remove_deleted_notion_pages_from_database(self):
        """
        Remove deleted Notion pages from MongoDB database

        This method identifies pages that no longer exist in Notion
        and removes them from our local database to maintain data consistency.
        """
        try:
            # notion_serviceë¥¼ ServiceManagerë¥¼ í†µí•´ ê°€ì ¸ì˜¤ê¸°
            from src.core.service_manager import service_manager

            notion_service = service_manager.get_service("notion")

            logger.debug("ğŸ§¹ ì‚­ì œëœ í˜ì´ì§€ ì •ë¦¬ ì‹œì‘")

            # DBì—ì„œ ëª¨ë“  í˜ì´ì§€ ID ê°€ì ¸ì˜¤ê¸°
            collection = get_meetup_collection("notion_pages")
            db_pages = await collection.find(
                {}, {"page_id": 1, "title": 1, "database_id": 1}
            ).to_list(length=None)

            if not db_pages:
                logger.debug("ğŸ“­ ì •ë¦¬í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
                return 0

            deleted_count = 0
            batch_size = 5  # ë°°ì¹˜ í¬ê¸° ì¤„ì„
            semaphore = asyncio.Semaphore(batch_size)

            async def check_and_clean_page(page):
                async with semaphore:
                    try:
                        page_id = page.get("page_id")
                        if not page_id:
                            return False

                        # check_page_exists ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ ì¡´ì¬ í™•ì¸
                        page_exists = await notion_service.check_page_exists(page_id)

                        if not page_exists:
                            # í˜ì´ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ DBì—ì„œ ì‚­ì œ
                            await collection.delete_one({"page_id": page_id})
                            logger.info(
                                f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€ ì •ë¦¬: {page.get('title', 'Unknown')} (ID: {page_id})"
                            )
                            return True
                        return False
                    except Exception as e:
                        logger.warning(f"âš ï¸ í˜ì´ì§€ í™•ì¸ ì‹¤íŒ¨: {page_id} - {e}")
                        return False

            # ë°°ì¹˜ë¡œ ë³‘ë ¬ ì²˜ë¦¬
            for i in range(0, len(db_pages), batch_size * 2):
                batch = db_pages[i : i + batch_size * 2]
                tasks = [check_and_clean_page(page) for page in batch]

                try:
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    deleted_count += sum(1 for result in results if result is True)

                    # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                    await asyncio.sleep(1)
                except Exception as batch_error:
                    logger.warning(f"âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {batch_error}")

            logger.info(f"âœ… ì‚­ì œëœ í˜ì´ì§€ ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ í˜ì´ì§€ ì œê±°")
            return deleted_count

        except Exception as e:
            logger.error(f"âŒ ì‚­ì œëœ í˜ì´ì§€ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0

    @safe_execution("sync_loop")
    async def _execute_continuous_sync_loop(self):
        """ë™ê¸°í™” ë£¨í”„"""
        while self.is_synchronization_running:
            try:
                # ì£¼ê¸°ì ìœ¼ë¡œ ì˜ëª»ëœ ë°ì´í„°ë² ì´ìŠ¤ í•­ëª©ê³¼ ì‚­ì œëœ í˜ì´ì§€ ì •ë¦¬ (1ì‹œê°„ë§ˆë‹¤)
                if (
                    not self._last_successful_sync_timestamp
                    or (datetime.now() - self._last_successful_sync_timestamp).seconds
                    > settings.cleanup_interval
                ):
                    await self.clean_invalid_database_entries()
                    await self.remove_deleted_notion_pages_from_database()
                    self._last_successful_sync_timestamp = datetime.now()

                await self.sync_notion_pages()
                await asyncio.sleep(self.synchronization_interval_seconds)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ ë™ê¸°í™” ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°

    @safe_execution("sync_notion_pages")
    async def sync_notion_pages(self):
        """Notion í˜ì´ì§€ ë™ê¸°í™”"""
        try:
            # MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì¬ì—°ê²°
            if (
                not mongodb_connection.connection_status
                or mongodb_connection.mongo_client is None
            ):
                await mongodb_connection.connect_database()

            collection = get_meetup_collection("notion_pages")

            # ì €ì¥ëœ ëª¨ë“  í˜ì´ì§€ ì¡°íšŒ
            stored_pages = await collection.find({}).to_list(None)

            # MongoDBì— í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ Notionì—ì„œ ê¸°ì¡´ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜´
            if not stored_pages:
                logger.info(
                    "ğŸ“­ MongoDBì— í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. Notionì—ì„œ ê¸°ì¡´ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."
                )
                await self._import_existing_notion_pages()
                stored_pages = await collection.find({}).to_list(None)

            total_pages = len(stored_pages)
            logger.info(f"ğŸ”„ ë™ê¸°í™” ì‹œì‘: {total_pages}ê°œ í˜ì´ì§€")

            deleted_pages = []
            updated_pages = []
            processed_count = 0

            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ í˜ì´ì§€ ë™ê¸°í™” (ê°œì„ ëœ ë²„ì „)
            import asyncio

            # í˜ì´ì§€ ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¸ë§ˆí¬ì–´ í¬ê¸° ì¡°ì •
            max_concurrent = min(5, max(2, total_pages // 10))  # 2-5 ì‚¬ì´ë¡œ ì¤„ì„
            semaphore = asyncio.Semaphore(max_concurrent)

            # notion_serviceë¥¼ ServiceManagerë¥¼ í†µí•´ ê°€ì ¸ì˜¤ê¸°
            from src.core.service_manager import service_manager

            notion_service = service_manager.get_service("notion")

            async def process_page(page):
                async with semaphore:
                    return await self._process_single_page(
                        page, notion_service, collection
                    )

            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
            batch_size = 20  # ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë” ìì£¼ ì§„í–‰ë¥  í‘œì‹œ
            all_results = []

            for i in range(0, len(stored_pages), batch_size):
                batch = stored_pages[i : i + batch_size]
                current_batch_end = min(i + batch_size, len(stored_pages))

                # ë°°ì¹˜ ì‹œì‘ ì‹œ ì§„í–‰ë¥  í‘œì‹œ
                progress_percent = (i / len(stored_pages)) * 100
                bar_length = 20
                filled_length = int(bar_length * progress_percent / 100)
                bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)

                logger.info(
                    f"ğŸ”„ [{bar}] {progress_percent:.0f}% ({i}/{len(stored_pages)}) ë°°ì¹˜ ì‹œì‘"
                )

                tasks = [process_page(page) for page in batch]

                # ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                completed_tasks = 0
                batch_results = []

                for task in asyncio.as_completed(tasks):
                    result = await task
                    batch_results.append(result)
                    completed_tasks += 1

                    # ê° íƒœìŠ¤í¬ ì™„ë£Œ ì‹œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    current_progress = ((i + completed_tasks) / len(stored_pages)) * 100
                    current_filled = int(bar_length * current_progress / 100)
                    current_bar = "â–ˆ" * current_filled + "â–‘" * (
                        bar_length - current_filled
                    )

                    # ì§„í–‰ë¥ ì´ 5% ì´ìƒ ì¦ê°€í–ˆì„ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥ (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
                    if current_progress - progress_percent >= 5:
                        logger.info(
                            f"ğŸ”„ [{current_bar}] {current_progress:.0f}% ({i + completed_tasks}/{len(stored_pages)})"
                        )
                        progress_percent = current_progress

                all_results.extend(batch_results)

                # ë°°ì¹˜ ì™„ë£Œ ì‹œ ìµœì¢… ì§„í–‰ë¥  í‘œì‹œ
                final_progress = (current_batch_end / len(stored_pages)) * 100
                final_filled = int(bar_length * final_progress / 100)
                final_bar = "â–ˆ" * final_filled + "â–‘" * (bar_length - final_filled)

                logger.info(
                    f"âœ… [{final_bar}] {final_progress:.0f}% ({current_batch_end}/{len(stored_pages)}) ë°°ì¹˜ ì™„ë£Œ"
                )

                # ë°°ì¹˜ ê°„ ì§§ì€ ëŒ€ê¸°ë¡œ API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
                if i + batch_size < len(stored_pages):
                    await asyncio.sleep(0.5)  # ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•

            results = all_results

            # ê²°ê³¼ ì²˜ë¦¬
            for result in results:
                if isinstance(result, Exception):
                    logger.warning(f"âš ï¸ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {result}")
                    processed_count += 1
                    continue

                if result and isinstance(result, tuple) and len(result) == 5:
                    page_id, title, thread_id, page_type, created_by = result
                    if page_id:  # ì‚­ì œëœ í˜ì´ì§€
                        deleted_pages.append(
                            {
                                "page_id": page_id,
                                "title": title,
                                "thread_id": thread_id,
                                "created_by": created_by,
                                "page_type": page_type,
                            }
                        )
                    else:  # ì—…ë°ì´íŠ¸ëœ í˜ì´ì§€
                        updated_pages.append(title)
                elif result:
                    logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ í˜•ì‹: {result}")

            # 3. ì‚­ì œëœ í˜ì´ì§€ì— ëŒ€í•œ ìŠ¤ë ˆë“œ ì²˜ë¦¬
            if deleted_pages:
                await self._handle_deleted_pages(deleted_pages)

            # 4. ë™ê¸°í™” ê²°ê³¼ ë¡œê¹… (ê·¸ë£¹í™”)
            if deleted_pages or updated_pages:
                logger.info(f"âœ… ë™ê¸°í™” ì™„ë£Œ: {total_pages}ê°œ í˜ì´ì§€ ì²˜ë¦¬")
                if deleted_pages:
                    logger.info(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€: {len(deleted_pages)}ê°œ")
                if updated_pages:
                    logger.info(f"ğŸ”„ ì—…ë°ì´íŠ¸ëœ í˜ì´ì§€: {len(updated_pages)}ê°œ")
            else:
                logger.info(
                    f"âœ… ë™ê¸°í™” ì™„ë£Œ: {total_pages}ê°œ í˜ì´ì§€ í™•ì¸ - ë³€ê²½ì‚¬í•­ ì—†ìŒ"
                )

        except Exception as e:
            logger.error(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        # finally ë¸”ë¡ ì œê±° - MongoDB ì—°ê²°ì„ ìœ ì§€í•´ì•¼ í•¨

    async def _process_single_page(self, page, notion_service, collection):
        """ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©, ìµœì í™”ë¨)"""
        try:
            page_id = page.get("page_id")
            title = page.get("title", "ì œëª© ì—†ìŒ")
            thread_id = page.get("thread_id")
            last_synced = page.get("last_synced", 0)

            # í˜ì´ì§€ ID ìœ íš¨ì„± ê²€ì‚¬
            if not page_id or not page_id.strip():
                logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ í˜ì´ì§€ ID, ì‚­ì œ: {title}")
                await collection.delete_one({"_id": page.get("_id")})
                return (
                    page_id,
                    title,
                    thread_id,
                    page.get("page_type"),
                    page.get("created_by"),
                )

            # ìµœê·¼ 2ì‹œê°„ ë‚´ì— ë™ê¸°í™”í–ˆë‹¤ë©´ ê°„ë‹¨ ì²´í¬ë§Œ ìˆ˜í–‰ (ìºì‹œ í™œìš© ê°•í™”)
            current_time = datetime.now().timestamp()
            if last_synced and (current_time - last_synced) < 7200:  # 2ì‹œê°„ = 7200ì´ˆ
                # ê°„ë‹¨í•œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸ (ë¡œê·¸ ì œê±°)
                page_exists = await notion_service.check_page_exists(page_id)
                if not page_exists:
                    await collection.delete_one({"page_id": page_id})
                    return (
                        page_id,
                        title,
                        thread_id,
                        page.get("page_type"),
                        page.get("created_by"),
                    )
                return None  # ë³€ê²½ì‚¬í•­ ì—†ìŒ

            # 1. í˜ì´ì§€ ë‚´ìš© ì—…ë°ì´íŠ¸ í™•ì¸ (ì¡´ì¬ ì—¬ë¶€ì™€ í•¨ê»˜)
            try:
                # extract_page_textë¡œ ì¡´ì¬ ì—¬ë¶€ì™€ ë‚´ìš©ì„ í•œ ë²ˆì— í™•ì¸ (ë¡œê·¸ ì œê±°)
                new_content = await notion_service.extract_page_text(
                    page_id, use_cache=True
                )

                # ë‚´ìš© ë³€ê²½ ì—¬ë¶€ í™•ì¸
                current_content = page.get("content", "")
                content_changed = new_content != current_content

                if content_changed or not last_synced:
                    # ë‚´ìš©ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ MongoDB ì—…ë°ì´íŠ¸
                    await collection.update_one(
                        {"page_id": page_id},
                        {
                            "$set": {
                                "content": new_content,
                                "content_length": len(new_content),
                                "last_synced": current_time,
                                "search_text": f"{title} {new_content}",
                            }
                        },
                    )
                    logger.debug(f"ğŸ”„ ë‚´ìš© ì—…ë°ì´íŠ¸ë¨: {title}")
                    return (None, title, None, None, None)  # ì—…ë°ì´íŠ¸ë¨
                else:
                    # ë‚´ìš©ì€ ê°™ì§€ë§Œ ë™ê¸°í™” ì‹œê°„ ì—…ë°ì´íŠ¸
                    await collection.update_one(
                        {"page_id": page_id}, {"$set": {"last_synced": current_time}}
                    )
                    return None  # ë³€ê²½ì‚¬í•­ ì—†ìŒ
            except Exception as update_error:
                logger.warning(f"âš ï¸ í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {title} - {update_error}")
                # extract_page_text ì‹¤íŒ¨ëŠ” í˜ì´ì§€ ì‚­ì œê°€ ì•„ë‹˜ - ê·¸ëƒ¥ ìŠ¤í‚µ
                logger.info(f"â­ï¸ í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ë¡œ ì¸í•œ ìŠ¤í‚µ: {title}")
                return None

        except Exception as e:
            if "404" in str(e) or "not found" in str(e).lower():
                # 404 ì˜¤ë¥˜ëŠ” í˜ì´ì§€ ë‚´ìš© ì‚­ì œë¡œ ê°„ì£¼ (MongoDBì—ì„œë§Œ ì œê±°)
                await collection.delete_one({"page_id": page_id})
                return (
                    page_id,
                    title,
                    thread_id,
                    page.get("page_type"),
                    page.get("created_by"),
                )
            else:
                logger.warning(f"âš ï¸ í˜ì´ì§€ í™•ì¸ ì‹¤íŒ¨: {title} - {e}")
                return None

    async def _import_existing_notion_pages(self):
        """Notion DBì—ì„œ ê¸°ì¡´ í˜ì´ì§€ë“¤ì„ MongoDBë¡œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            logger.info("ğŸ“¥ Notion DBì—ì„œ ê¸°ì¡´ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ë° ì—°ê²°
            if (
                not mongodb_connection.connection_status
                or mongodb_connection.mongo_client is None
            ):
                await mongodb_connection.connect_database()

            # Factory Tracker DBì—ì„œ í˜ì´ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
            factory_pages = await self._get_notion_database_pages("factory_tracker")
            logger.info(f"ğŸ“Š Factory Trackerì—ì„œ {len(factory_pages)}ê°œ í˜ì´ì§€ ë°œê²¬")

            # Board DBì—ì„œ í˜ì´ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
            board_pages = await self._get_notion_database_pages("board")
            logger.info(f"ğŸ“‹ Boardì—ì„œ {len(board_pages)}ê°œ í˜ì´ì§€ ë°œê²¬")

            # ëª¨ë“  í˜ì´ì§€ë¥¼ MongoDBì— ì €ì¥
            all_pages = factory_pages + board_pages
            if all_pages:
                collection = get_meetup_collection("notion_pages")
                await collection.insert_many(all_pages)
                logger.info(f"âœ… {len(all_pages)}ê°œ í˜ì´ì§€ë¥¼ MongoDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            else:
                logger.info("ğŸ“­ Notion DBì—ì„œ ê°€ì ¸ì˜¬ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"âŒ ê¸°ì¡´ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    async def _get_notion_database_pages(self, db_type: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • Notion DBì—ì„œ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # notion_serviceë¥¼ ServiceManagerë¥¼ í†µí•´ ê°€ì ¸ì˜¤ê¸°
            from src.core.service_manager import service_manager

            notion_service = service_manager.get_service("notion")

            if db_type == "factory_tracker":
                db_id = settings.factory_tracker_db_id
                page_type = "task"
            elif db_type == "board":
                db_id = settings.board_db_id
                page_type = "meeting"
            else:
                return []

            # Notion DBì—ì„œ í˜ì´ì§€ë“¤ ì¡°íšŒ
            response = notion_service.notion_api_client.databases.query(
                database_id=db_id, page_size=100
            )

            logger.info(
                f"ğŸ” {db_type} DB ì‘ë‹µ: {len(response.get('results', []))}ê°œ í˜ì´ì§€ ë°œê²¬"
            )

            # ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ í˜ì´ì§€ë“¤ ì²˜ë¦¬
            pages = await self._process_pages_parallel(
                response.get("results", []), db_type, db_id, page_type
            )

            return pages

        except Exception as e:
            logger.error(f"âŒ {db_type} DBì—ì„œ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    async def _process_pages_parallel(
        self,
        page_data_list: List[Dict[str, Any]],
        db_type: str,
        db_id: str,
        page_type: str,
    ) -> List[Dict[str, Any]]:
        """í˜ì´ì§€ë“¤ì„ ë¹„ë™ê¸° ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
        try:
            # ë™ì‹œ ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜ ì œí•œ (API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ê³ ë ¤)
            BATCH_SIZE = 5
            semaphore = asyncio.Semaphore(BATCH_SIZE)

            async def process_single_page(
                page_data: Dict[str, Any],
            ) -> Optional[Dict[str, Any]]:
                """ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬"""
                async with semaphore:
                    try:
                        # í˜ì´ì§€ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                        page_id = page_data["id"]
                        title = self._extract_page_title(page_data, db_type)

                        if not title:
                            logger.warning(f"âš ï¸ ì œëª©ì´ ì—†ëŠ” í˜ì´ì§€ ìŠ¤í‚µ: {page_id}")
                            return None

                        # notion_serviceë¥¼ ServiceManagerë¥¼ í†µí•´ ê°€ì ¸ì˜¤ê¸°
                        from src.core.service_manager import service_manager

                        notion_service = service_manager.get_service("notion")

                        # í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ ì‹œë„ (ë³‘ë ¬ ì²˜ë¦¬)
                        try:
                            content = await notion_service.extract_page_text(page_id)
                        except:
                            content = ""

                        # MongoDBì— ì €ì¥í•  ë°ì´í„° êµ¬ì„±
                        page_doc = {
                            "page_id": page_id,
                            "database_id": db_id,
                            "title": title,
                            "content": content,
                            "content_length": len(content),
                            "page_type": page_type,
                            "database_type": db_type,
                            "created_time": page_data.get("created_time", ""),
                            "last_edited_time": page_data.get("last_edited_time", ""),
                            "created_by": str(
                                page_data.get("created_by", {}).get("id", "unknown")
                            ),
                            "last_edited_by": str(
                                page_data.get("last_edited_by", {}).get("id", "unknown")
                            ),
                            "url": page_data.get("url", ""),
                            "thread_id": None,
                            "last_synced": datetime.now().timestamp(),
                            "search_text": f"{title} {content}",
                        }

                        return page_doc

                    except Exception as page_error:
                        logger.warning(f"âš ï¸ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {page_error}")
                        return None

            # ëª¨ë“  í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
            tasks = [process_single_page(page_data) for page_data in page_data_list]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
            pages = [
                page
                for page in results
                if page is not None and not isinstance(page, Exception)
            ]

            logger.info(f"âœ… {db_type} ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {len(pages)}ê°œ í˜ì´ì§€")
            return pages

        except Exception as e:
            logger.error(f"âŒ ë³‘ë ¬ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def _extract_page_title(self, page_data: Dict[str, Any], db_type: str) -> str:
        """í˜ì´ì§€ì—ì„œ ì œëª© ì¶”ì¶œ"""
        try:
            properties = page_data.get("properties", {})

            if db_type == "factory_tracker":
                # Factory Trackerì˜ Task name ì†ì„± (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì´ë¦„ ì‹œë„)
                for title_key in ["Task name", "Title", "Name", "title", "name"]:
                    title_prop = properties.get(title_key, {})
                    if title_prop.get("type") == "title":
                        title_blocks = title_prop.get("title", [])
                        if title_blocks:
                            return title_blocks[0].get("plain_text", "")

            elif db_type == "board":
                # Boardì˜ Name ì†ì„± (Titleì´ ì•„ë‹ˆë¼ Name)
                name_prop = properties.get("Name", {})
                if name_prop.get("type") == "title":
                    title_blocks = name_prop.get("title", [])
                    if title_blocks:
                        return title_blocks[0].get("plain_text", "")

            return ""

        except Exception as e:
            logger.warning(f"âš ï¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    async def _update_page_content(self, page: Dict[str, Any]) -> bool:
        """í˜ì´ì§€ ë‚´ìš© ì—…ë°ì´íŠ¸"""
        try:
            page_id = page.get("page_id")
            current_content = page.get("content", "")
            current_sync_time = page.get("last_synced", 0)

            # ìµœê·¼ 1ì‹œê°„ ë‚´ì— ë™ê¸°í™”í–ˆë‹¤ë©´ ìŠ¤í‚µ
            if (
                current_sync_time
                and (datetime.now().timestamp() - current_sync_time) < 3600
            ):
                return False

            # í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ
            try:
                new_content = await notion_service.extract_page_text(page_id)
            except Exception as extract_error:
                # 404 ì˜¤ë¥˜ëŠ” í˜ì´ì§€ ë‚´ìš© ì‚­ì œë¡œ ê°„ì£¼í•˜ê³  ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
                if (
                    "404" in str(extract_error)
                    or "not found" in str(extract_error).lower()
                ):
                    logger.info(f"ğŸ” 404 ì˜¤ë¥˜ ê°ì§€í•˜ì—¬ ì˜ˆì™¸ ì¬ë°œìƒ: {extract_error}")
                    raise extract_error
                else:
                    # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ë¡œê¹…í•˜ê³  False ë°˜í™˜
                    logger.warning(f"âš ï¸ í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {extract_error}")
                    return False

            if new_content != current_content:
                # ë‚´ìš©ì´ ë³€ê²½ë¨
                collection = get_meetup_collection("notion_pages")
                await collection.update_one(
                    {"page_id": page_id},
                    {
                        "$set": {
                            "content": new_content,
                            "content_length": len(new_content),
                            "last_synced": datetime.now().timestamp(),
                            "search_text": f"{page.get('title', '')} {new_content}",
                        }
                    },
                )
                return True

            return False

        except Exception as e:
            logger.warning(f"âš ï¸ í˜ì´ì§€ ë‚´ìš© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    @safe_execution("handle_deleted_pages")
    async def _handle_deleted_pages(self, deleted_pages: List[Dict[str, Any]]):
        """ì‚­ì œëœ í˜ì´ì§€ì— ëŒ€í•œ ìŠ¤ë ˆë“œ ì²˜ë¦¬"""
        for page in deleted_pages:
            try:
                thread_id = page.get("thread_id")
                title = page.get("title", "ì œëª© ì—†ìŒ")
                page_type = page.get("page_type", "unknown")
                created_by = page.get("created_by", "unknown")

                if not thread_id:
                    logger.warning(f"âš ï¸ ìŠ¤ë ˆë“œ IDê°€ ì—†ëŠ” ì‚­ì œëœ í˜ì´ì§€: {title}")
                    continue

                # ìŠ¤ë ˆë“œì— ì‚­ì œ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡
                await self._send_deletion_notification(thread_id, page)

                # ìŠ¤ë ˆë“œëŠ” ë¹„í™œì„±í™”í•˜ì§€ ì•ŠìŒ (í˜ì´ì§€ ìì²´ëŠ” ì‚­ì œë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ)
                # ê°œë³„ ë¡œê·¸ ì œê±° - ìš”ì•½ì—ì„œë§Œ í‘œì‹œ

            except Exception as e:
                logger.error(f"âŒ ì‚­ì œëœ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    @safe_execution("send_deletion_notification")
    async def _send_deletion_notification(self, thread_id: int, page: Dict[str, Any]):
        """ì‚­ì œ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            title = page.get("title", "ì œëª© ì—†ìŒ")
            page_type = page.get("page_type", "unknown")
            created_by = page.get("created_by", "unknown")

            # ì‚­ì œ ì•Œë¦¼ ë©”ì‹œì§€ êµ¬ì„±
            embed = {
                "title": "ğŸ—‘ï¸ í˜ì´ì§€ ë‚´ìš© ì‚­ì œë¨",
                "description": f"**{title}** í˜ì´ì§€ì˜ ë‚´ìš©ì´ Notionì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "color": 0xFF6B6B,  # ë¹¨ê°„ìƒ‰
                "fields": [
                    {
                        "name": "ğŸ“„ í˜ì´ì§€ ì •ë³´",
                        "value": f"**ì œëª©**: {title}\n**íƒ€ì…**: {page_type}\n**ìƒì„±ì**: User {created_by[-4:]}",
                        "inline": False,
                    },
                    {
                        "name": "âš ï¸ ì£¼ì˜ì‚¬í•­",
                        "value": "ì´ í˜ì´ì§€ëŠ” ë” ì´ìƒ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nìƒˆë¡œìš´ í˜ì´ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´ `/meeting`, `/task`, `/document` ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
                        "inline": False,
                    },
                ],
                "timestamp": datetime.now().isoformat(),
                "footer": {"text": "DinoBot ë™ê¸°í™” ì‹œìŠ¤í…œ"},
            }

            # Discord ìŠ¤ë ˆë“œì— ë©”ì‹œì§€ ì „ì†¡
            await discord_service.send_thread_message(
                thread_id=thread_id, content="", embed=embed
            )

            logger.info(f"ğŸ“¢ ì‚­ì œ ì•Œë¦¼ ì „ì†¡: {title}")

        except Exception as e:
            logger.error(f"âŒ ì‚­ì œ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

    @safe_execution("deactivate_thread")
    async def _deactivate_thread(self, thread_id: int, page: Dict[str, Any]):
        """ìŠ¤ë ˆë“œ ë¹„í™œì„±í™”"""
        try:
            # Discord ìŠ¤ë ˆë“œ ë¹„í™œì„±í™” (archived ìƒíƒœë¡œ ë³€ê²½)
            thread = discord_service.bot.get_channel(thread_id)
            if thread and hasattr(thread, "edit"):
                await thread.edit(archived=True, locked=True)
                logger.info(f"ğŸ”’ ìŠ¤ë ˆë“œ ë¹„í™œì„±í™”: {thread_id}")
            else:
                logger.warning(f"âš ï¸ ìŠ¤ë ˆë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {thread_id}")

        except Exception as e:
            logger.error(f"âŒ ìŠ¤ë ˆë“œ ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")

    @safe_execution("manual_sync")
    async def manual_sync(self) -> Dict[str, Any]:
        """ìˆ˜ë™ ë™ê¸°í™” ì‹¤í–‰"""
        try:
            # MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì¬ì—°ê²°
            if (
                not mongodb_connection.connection_status
                or mongodb_connection.mongo_client is None
            ):
                await mongodb_connection.connect_database()

            collection = get_meetup_collection("notion_pages")

            # ì €ì¥ëœ í˜ì´ì§€ ìˆ˜
            total_pages = await collection.count_documents({})

            # ë™ê¸°í™” ì‹¤í–‰
            await self.sync_notion_pages()

            # ê²°ê³¼ ë°˜í™˜
            return {
                "success": True,
                "message": "ë™ê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "total_pages": total_pages,
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"âŒ ìˆ˜ë™ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "message": f"ë™ê¸°í™” ì‹¤íŒ¨: {e}",
                "timestamp": datetime.now().isoformat(),
            }
        # finally ë¸”ë¡ ì œê±° - MongoDB ì—°ê²°ì„ ìœ ì§€í•´ì•¼ í•¨

    @safe_execution("get_sync_status")
    async def get_sync_status(self) -> Dict[str, Any]:
        """ë™ê¸°í™” ìƒíƒœ ì¡°íšŒ"""
        try:
            # MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì¬ì—°ê²°
            if (
                not mongodb_connection.connection_status
                or mongodb_connection.mongo_client is None
            ):
                await mongodb_connection.connect_database()

            collection = get_meetup_collection("notion_pages")

            # ì „ì²´ í˜ì´ì§€ ìˆ˜
            total_pages = await collection.count_documents({})

            # ìµœê·¼ ë™ê¸°í™”ëœ í˜ì´ì§€ ìˆ˜
            recent_sync = await collection.count_documents(
                {
                    "last_synced": {
                        "$gte": datetime.now().timestamp() - 3600
                    }  # ìµœê·¼ 1ì‹œê°„
                }
            )

            # í˜ì´ì§€ íƒ€ì…ë³„ ë¶„í¬
            type_distribution = {}
            cursor = collection.aggregate(
                [{"$group": {"_id": "$page_type", "count": {"$sum": 1}}}]
            )

            async for doc in cursor:
                type_distribution[doc["_id"]] = doc["count"]

            return {
                "is_running": self.is_synchronization_running,
                "total_pages": total_pages,
                "recent_sync": recent_sync,
                "type_distribution": type_distribution,
                "sync_interval": self.synchronization_interval_seconds,
                "last_check": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"âŒ ë™ê¸°í™” ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "is_running": False,
                "error": str(e),
                "last_check": datetime.now().isoformat(),
            }
        # finally ë¸”ë¡ ì œê±° - MongoDB ì—°ê²°ì„ ìœ ì§€í•´ì•¼ í•¨


# Global sync service instance
sync_service = SyncService()
