"""
ê²€ìƒ‰ ì„œë¹„ìŠ¤ ëª¨ë“ˆ
- ì œëª© ë° ë‚´ìš© ê¸°ë°˜ í˜ì´ì§€ ê²€ìƒ‰
- íƒ€ì… ë° ì‚¬ìš©ì í•„í„°ë§
- MongoDB í…ìŠ¤íŠ¸ ê²€ìƒ‰ í™œìš©
"""

import re
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta

from src.core.database import get_meetup_collection, mongodb_connection
from src.core.logger import get_logger
from src.core.exceptions import safe_execution

# notion_serviceëŠ” ServiceManagerë¥¼ í†µí•´ ì ‘ê·¼
# from services.notion import notion_service

logger = get_logger("services.search")


class SearchService:
    """í˜ì´ì§€ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""

    def __init__(self):
        # ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë¡œê·¸ ì œê±°)
        pass

    @safe_execution("search_pages")
    async def search_pages(
        self,
        query: str,
        page_type: str = None,
        user_filter: str = None,
        days_limit: int = 90,
        days: int = None,  # í˜¸í™˜ì„±ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
        limit: int = 20,
    ) -> Dict[str, Any]:
        """
        í˜ì´ì§€ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ í‚¤ì›Œë“œ
            page_type: í˜ì´ì§€ íƒ€ì… í•„í„° (meeting, task, note)
            user_filter: ì‚¬ìš©ì ID í•„í„°
            days_limit: ê²€ìƒ‰ ê¸°ê°„ ì œí•œ (ì¼)
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ
        """
        # í˜¸í™˜ì„±ì„ ìœ„í•œ days íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        if days is not None:
            days_limit = days

        if not query or len(query.strip()) < 2:
            return {
                "total_results": 0,
                "results": [],
                "query": query,
                "filters": {"type": page_type, "user": user_filter, "days": days_limit},
            }

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ë° ì—°ê²°
        if (
            not mongodb_connection.connection_status
            or mongodb_connection.mongo_client is None
        ):
            await mongodb_connection.connect_database()

        collection = get_meetup_collection("notion_pages")

        # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •
        search_conditions = []

        # ë‚ ì§œ ë²”ìœ„ í•„í„° (ì„ì‹œë¡œ ë¹„í™œì„±í™” - ëª¨ë“  í˜ì´ì§€ ê²€ìƒ‰)
        # if days_limit is None:
        #     days_limit = 90  # ê¸°ë³¸ê°’ ì„¤ì •
        # since_date = datetime.now() - timedelta(days=days_limit)
        # # created_atì´ Noneì´ê±°ë‚˜ ë‚ ì§œ ë²”ìœ„ì— í¬í•¨ë˜ëŠ” ê²½ìš°
        # search_conditions.append(
        #     {
        #         "$or": [
        #             {"created_at": {"$gte": since_date}},
        #             {"created_at": None},
        #             {"created_at": {"$exists": False}},
        #             {"created_at": {"$type": "null"}},
        #         ]
        #     }
        # )

        # íƒ€ì… í•„í„°
        if page_type and page_type != "all":
            search_conditions.append({"page_type": page_type})

        # ì‚¬ìš©ì í•„í„°
        if user_filter and user_filter != "all":
            search_conditions.append({"created_by": user_filter})

        # MongoDB ì¿¼ë¦¬ ì‹¤í–‰ (ì •ê·œì‹ ì œì™¸)
        if len(search_conditions) > 1:
            mongo_query = {"$and": search_conditions}
        else:
            mongo_query = search_conditions[0] if search_conditions else {}

        # ëª¨ë“  í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° (Python ë ˆë²¨ì—ì„œ í•„í„°ë§)
        all_pages = await collection.find(mongo_query).to_list(None)

        # Python ë ˆë²¨ì—ì„œ ì œëª© ê²€ìƒ‰ (ì •í™• ë§¤ì¹­ + ìœ ì‚¬ë„ ê²€ìƒ‰)
        title_results = []
        query_lower = query.lower()
        query_words = set(query_lower.split())

        for page in all_pages:
            title = page.get("title", "")
            title_lower = title.lower()
            title_words = set(title_lower.split())

            # 1. ì •í™•í•œ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ (ë†’ì€ ìš°ì„ ìˆœìœ„)
            if query_lower in title_lower:
                page["_match_score"] = 100
                title_results.append(page)
            # 2. ë‹¨ì–´ ë‹¨ìœ„ ìœ ì‚¬ë„ ê²€ìƒ‰
            elif query_words and title_words:
                # ê³µí†µ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
                common_words = query_words.intersection(title_words)
                if common_words:
                    # ìœ ì‚¬ë„ ì ìˆ˜ = (ê³µí†µ ë‹¨ì–´ ìˆ˜ / ì „ì²´ ê²€ìƒ‰ì–´ ìˆ˜) * 50
                    similarity_score = (len(common_words) / len(query_words)) * 50
                    page["_match_score"] = similarity_score
                    title_results.append(page)

            if len(title_results) >= limit * 2:  # ë” ë§ì€ í›„ë³´ë¥¼ ìˆ˜ì§‘
                break

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        title_results.sort(key=lambda x: x.get("_match_score", 0), reverse=True)
        title_results = title_results[:limit]

        logger.info(f"ğŸ” ì œëª© ê²€ìƒ‰ ì™„ë£Œ: '{query}' -> {len(title_results)}ê°œ ê²°ê³¼")

        # ë‚´ìš© ê²€ìƒ‰ (Notion API í™œìš©)
        content_results = []
        if len(title_results) < limit:
            content_results = await self._search_in_content(
                query, page_type, user_filter, days_limit, limit - len(title_results)
            )

        # ê²°ê³¼ í•©ì¹˜ê¸° ë° ì¤‘ë³µ ì œê±°
        all_results = title_results + content_results
        unique_results = []
        seen_page_ids = set()

        for result in all_results:
            page_id = result.get("page_id")
            if page_id not in seen_page_ids:
                seen_page_ids.add(page_id)
                # ê²€ìƒ‰ ê²°ê³¼ì— ì¶”ê°€ ì •ë³´ í¬í•¨
                enhanced_result = self._enhance_search_result(result)
                unique_results.append(enhanced_result)

        # ê²°ê³¼ë¥¼ ìƒì„± ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        unique_results.sort(
            key=lambda x: x.get("created_at", datetime.min), reverse=True
        )

        # ê²°ê³¼ ê°œìˆ˜ ì œí•œ
        final_results = unique_results[:limit]

        logger.info(f"ğŸ” ì „ì²´ ê²€ìƒ‰ ì™„ë£Œ: '{query}' -> {len(final_results)}ê°œ ìµœì¢… ê²°ê³¼")

        # ê²€ìƒ‰ ì œì•ˆ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ê°€ ì ê±°ë‚˜ ì—†ì„ ë•Œ)
        suggestions = {}
        if len(final_results) < 10:
            suggestions = await self.get_search_suggestions(query)

        return {
            "total_results": len(final_results),
            "results": final_results,
            "query": query,
            "filters": {"type": page_type, "user": user_filter, "days": days_limit},
            "suggestions": suggestions,
        }

    @safe_execution("search_in_content")
    async def _search_in_content(
        self,
        query: str,
        page_type: str = None,
        user_filter: str = None,
        days_limit: int = 90,
        limit: int = 10,
    ) -> List[Dict[str, Any]]:
        """í˜ì´ì§€ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ë° ì—°ê²°
            if (
                not mongodb_connection.connection_status
                or mongodb_connection.mongo_client is None
            ):
                await mongodb_connection.connect_database()

            collection = get_meetup_collection("notion_pages")

            # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì • (ì œëª© ê²€ìƒ‰ê³¼ ë™ì¼)
            search_conditions = []

            # since_date = datetime.now() - timedelta(days=days_limit)
            # # created_atì´ Noneì´ê±°ë‚˜ ë‚ ì§œ ë²”ìœ„ì— í¬í•¨ë˜ëŠ” ê²½ìš°
            # search_conditions.append(
            #     {
            #         "$or": [
            #             {"created_at": {"$gte": since_date}},
            #             {"created_at": None},
            #             {"created_at": {"$exists": False}},
            #             {"created_at": {"$type": "null"}},
            #         ]
            #     }
            # )

            if page_type and page_type != "all":
                search_conditions.append({"page_type": page_type})

            if user_filter and user_filter != "all":
                search_conditions.append({"created_by": user_filter})

            # ê¸°ë³¸ ì¿¼ë¦¬
            if len(search_conditions) > 1:
                mongo_query = {"$and": search_conditions}
            else:
                mongo_query = search_conditions[0] if search_conditions else {}

            # ìµœê·¼ í˜ì´ì§€ë“¤ ê°€ì ¸ì˜¤ê¸° (ë‚´ìš© ê²€ìƒ‰ ëŒ€ìƒ)
            pages = await collection.find(mongo_query).limit(100).to_list(None)

            content_matches = []
            query_lower = query.lower()

            for page in pages:
                try:
                    # Notionì—ì„œ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    page_content = await notion_service.extract_page_text(
                        page_id=page["page_id"]
                    )

                    # ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                    if page_content and query_lower in page_content.lower():
                        # ë§¤ì¹­ëœ ë¶€ë¶„ ì°¾ê¸° (ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜)
                        content_preview = self._extract_search_context(
                            page_content, query
                        )

                        # í˜ì´ì§€ ì •ë³´ì— ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
                        page_with_context = page.copy()
                        page_with_context["search_context"] = content_preview
                        page_with_context["match_type"] = "content"

                        content_matches.append(page_with_context)

                        if len(content_matches) >= limit:
                            break

                except Exception as e:
                    logger.warning(
                        f"âš ï¸ í˜ì´ì§€ ë‚´ìš© ê²€ìƒ‰ ì‹¤íŒ¨ ({page.get('page_id')}): {e}"
                    )
                    continue

            logger.info(
                f"ğŸ” ë‚´ìš© ê²€ìƒ‰ ì™„ë£Œ: '{query}' -> {len(content_matches)}ê°œ ê²°ê³¼"
            )
            return content_matches

        except Exception as e:
            logger.error(f"âŒ ë‚´ìš© ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _extract_search_context(
        self, content: str, query: str, context_length: int = 100
    ) -> str:
        """ê²€ìƒ‰ì–´ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            query_lower = query.lower()
            content_lower = content.lower()

            # ì²« ë²ˆì§¸ ë§¤ì¹­ ìœ„ì¹˜ ì°¾ê¸°
            match_pos = content_lower.find(query_lower)
            if match_pos == -1:
                return (
                    content[:context_length] + "..."
                    if len(content) > context_length
                    else content
                )

            # ì»¨í…ìŠ¤íŠ¸ ë²”ìœ„ ê³„ì‚°
            start = max(0, match_pos - context_length // 2)
            end = min(len(content), match_pos + len(query) + context_length // 2)

            context = content[start:end]

            # ì•ë’¤ì— ... ì¶”ê°€
            if start > 0:
                context = "..." + context
            if end < len(content):
                context = context + "..."

            return context

        except Exception as e:
            logger.warning(f"âš ï¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return (
                content[:context_length] + "..."
                if len(content) > context_length
                else content
            )

    def _enhance_search_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ì— ì¶”ê°€ ì •ë³´ í¬í•¨"""
        try:
            enhanced = result.copy()

            # Notion í˜ì´ì§€ ë§í¬ ìƒì„±
            page_id = result.get("page_id", "")
            if page_id:
                enhanced["notion_url"] = f"https://notion.so/{page_id.replace('-', '')}"

            # ì£¼ìš” í”„ë¡œí¼í‹° ì¶”ì¶œ (ê¸°ì¡´ í•„ë“œë“¤ ì‚¬ìš©)
            main_properties = {}

            # ê¸°ë³¸ ì •ë³´ë“¤
            if result.get("page_type"):
                main_properties["í˜ì´ì§€ íƒ€ì…"] = result.get("page_type")
            if result.get("database_type"):
                main_properties["ë°ì´í„°ë² ì´ìŠ¤"] = result.get("database_type")
            if result.get("created_by"):
                main_properties["ìƒì„±ì"] = result.get("created_by")
            if result.get("created_time"):
                main_properties["ìƒì„±ì¼"] = result.get("created_time")
            if result.get("last_edited_time"):
                main_properties["ìˆ˜ì •ì¼"] = result.get("last_edited_time")

            # Notion propertiesê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            properties = result.get("properties", {})
            for key, value in properties.items():
                if value is not None and value != "" and value != []:
                    # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                    if isinstance(value, str) and len(value) > 100:
                        value = value[:100] + "..."
                    main_properties[key] = value

            enhanced["main_properties"] = main_properties

            # ê²€ìƒ‰ ë§¤ì¹­ íƒ€ì… í‘œì‹œ
            if "search_context" in result:
                enhanced["match_type"] = "content"
            elif result.get("_match_score", 0) > 0:
                enhanced["match_type"] = "title"
            else:
                enhanced["match_type"] = "unknown"

            return enhanced

        except Exception as e:
            logger.warning(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ê°•í™” ì‹¤íŒ¨: {e}")
            return result

    @safe_execution("get_related_keywords")
    async def get_related_keywords(self, query: str, limit: int = 5) -> List[str]:
        """ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì²œ"""
        try:
            collection = get_meetup_collection("notion_pages")

            # í˜„ì¬ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ í˜ì´ì§€ë“¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            query_regex = re.compile(re.escape(query), re.IGNORECASE)
            related_pages = (
                await collection.find({"title": {"$regex": query_regex}})
                .limit(20)
                .to_list(None)
            )

            # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = set()
            for page in related_pages:
                title = page.get("title", "")
                # ì œëª©ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬í•˜ê³  2ê¸€ì ì´ìƒì¸ ê²ƒë§Œ ì¶”ì¶œ
                words = re.findall(r"\b\w{2,}\b", title)
                for word in words:
                    if word.lower() != query.lower() and len(word) >= 2:
                        keywords.add(word)

            # ìµœê·¼ì— ë§ì´ ì‚¬ìš©ëœ í‚¤ì›Œë“œë“¤ì„ ìš°ì„ ìˆœìœ„ë¡œ
            keyword_freq = {}
            for keyword in keywords:
                count = await collection.count_documents(
                    {"title": {"$regex": re.compile(re.escape(keyword), re.IGNORECASE)}}
                )
                keyword_freq[keyword] = count

            # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_keywords = sorted(
                keyword_freq.items(), key=lambda x: x[1], reverse=True
            )

            return [keyword for keyword, _ in sorted_keywords[:limit]]

        except Exception as e:
            logger.warning(f"âš ï¸ ì—°ê´€ ê²€ìƒ‰ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    @safe_execution("get_search_suggestions")
    async def get_search_suggestions(self, query: str) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì œì•ˆ ë° ì¶”ì²œ"""
        try:
            collection = get_meetup_collection("notion_pages")

            suggestions = {
                "did_you_mean": [],
                "related_keywords": [],
                "popular_searches": [],
                "recent_activity": [],
            }

            # 1. ì˜¤íƒ€ êµì • ì œì•ˆ (ê°„ë‹¨í•œ ë°©ì‹)
            if len(query) > 3:
                # ë¹„ìŠ·í•œ ì œëª©ë“¤ ì°¾ê¸°
                similar_titles = (
                    await collection.find(
                        {
                            "title": {
                                "$regex": re.compile(f".*{query[:-1]}.*", re.IGNORECASE)
                            }
                        }
                    )
                    .limit(3)
                    .to_list(None)
                )

                for page in similar_titles:
                    title_words = re.findall(r"\b\w+\b", page.get("title", ""))
                    for word in title_words:
                        if len(word) > 2 and word.lower() != query.lower():
                            if self._is_similar(query, word):
                                suggestions["did_you_mean"].append(word)

            # 2. ì—°ê´€ ê²€ìƒ‰ì–´
            suggestions["related_keywords"] = await self.get_related_keywords(query)

            # 3. ì¸ê¸° ê²€ìƒ‰ì–´ (ìµœê·¼ í™œë™ì´ ë§ì€ í‚¤ì›Œë“œë“¤)
            recent_pages = (
                await collection.find({}).sort("created_at", -1).limit(20).to_list(None)
            )
            word_counts = {}
            for page in recent_pages:
                words = re.findall(r"\b\w{2,}\b", page.get("title", ""))
                for word in words:
                    word_counts[word] = word_counts.get(word, 0) + 1

            popular = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            suggestions["popular_searches"] = [
                word for word, _ in popular if word.lower() != query.lower()
            ]

            # 4. ìµœê·¼ í™œë™
            recent_activity = (
                await collection.find({}).sort("created_at", -1).limit(5).to_list(None)
            )
            suggestions["recent_activity"] = [
                {
                    "title": page.get("title", ""),
                    "type": page.get("page_type", "unknown"),
                    "created_at": page.get("created_at"),
                }
                for page in recent_activity
            ]

            return suggestions

        except Exception as e:
            logger.warning(f"âš ï¸ ê²€ìƒ‰ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "did_you_mean": [],
                "related_keywords": [],
                "popular_searches": [],
                "recent_activity": [],
            }

    def _is_similar(self, word1: str, word2: str, threshold: float = 0.7) -> bool:
        """ë‘ ë‹¨ì–´ì˜ ìœ ì‚¬ë„ ê²€ì‚¬ (ê°„ë‹¨í•œ í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜)"""
        if abs(len(word1) - len(word2)) > 2:
            return False

        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê²€ì‚¬
        common_chars = set(word1.lower()) & set(word2.lower())
        similarity = len(common_chars) / max(len(word1), len(word2))
        return similarity >= threshold

    def format_search_results(self, search_data: Dict[str, Any]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ Discord ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (ì—°ê´€ ê²€ìƒ‰ì–´ í¬í•¨)"""
        query = search_data.get("query", "")
        total = search_data.get("total_results", 0)
        results = search_data.get("results", [])
        filters = search_data.get("filters", {})
        suggestions = search_data.get("suggestions", {})

        if total == 0:
            msg = f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ**\n"
            msg += f"ê²€ìƒ‰ì–´: `{query}`\n\n"

            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ì œì•ˆ í‘œì‹œ
            if suggestions:
                if suggestions.get("did_you_mean"):
                    msg += f"ğŸ¤” **ì´ê²ƒì„ ì°¾ìœ¼ì…¨ë‚˜ìš”?**: {', '.join(suggestions['did_you_mean'][:3])}\n\n"

                if suggestions.get("related_keywords"):
                    msg += f"ğŸ’¡ **ì—°ê´€ ê²€ìƒ‰ì–´**: {', '.join(suggestions['related_keywords'][:5])}\n\n"

                if suggestions.get("popular_searches"):
                    msg += f"ğŸ”¥ **ì¸ê¸° ê²€ìƒ‰ì–´**: {', '.join(suggestions['popular_searches'][:5])}\n\n"

                if suggestions.get("recent_activity"):
                    msg += "ğŸ“‹ **ìµœê·¼ í™œë™**:\n"
                    for activity in suggestions["recent_activity"][:3]:
                        msg += f"   â€¢ {activity['title']} ({activity['type']})\n"
            else:
                msg += "ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."

            return msg

        msg = f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼** (`{query}`)\n"
        msg += f"ğŸ“Š ì´ {total}ê°œ ê²°ê³¼"

        # í•„í„° ì •ë³´ í‘œì‹œ
        filter_info = []
        if filters.get("type") and filters["type"] != "all":
            filter_info.append(f"íƒ€ì…: {filters['type']}")
        if filters.get("user") and filters["user"] != "all":
            filter_info.append(f"ì‚¬ìš©ì: {filters['user'][-4:]}")
        if filters.get("days"):
            filter_info.append(f"ìµœê·¼ {filters['days']}ì¼")

        if filter_info:
            msg += f" ({', '.join(filter_info)})"

        msg += "\n\n"

        # ê²°ê³¼ ëª©ë¡
        for i, result in enumerate(results[:8], 1):  # 8ê°œë¡œ ì¤„ì—¬ì„œ ì œì•ˆ ê³µê°„ í™•ë³´
            title = result.get("title", "ì œëª© ì—†ìŒ")
            page_type = result.get("page_type", "unknown")
            created_at = result.get("created_at")
            user_id = result.get("created_by", "unknown")

            # íƒ€ì… ì´ëª¨ì§€
            type_emoji = (
                "ğŸ“"
                if page_type == "note"
                else (
                    "ğŸ“…"
                    if page_type == "meeting"
                    else ("âœ…" if page_type == "task" else "ğŸ“„")
                )
            )

            # ë‚ ì§œ í¬ë§·
            date_str = "ë‚ ì§œ ë¯¸ìƒ"
            if created_at:
                if isinstance(created_at, datetime):
                    date_str = created_at.strftime("%m/%d %H:%M")
                else:
                    date_str = str(created_at)[:10]  # YYYY-MM-DDë§Œ

            # ë…¸ì…˜ í˜ì´ì§€ ë§í¬ ì¶”ê°€
            notion_url = result.get("notion_url", "")

            msg += f"{type_emoji} **{title}**\n"
            msg += f"   ğŸ“… {date_str} | ğŸ‘¤ User {user_id[-4:]} | ğŸ“‚ {page_type}\n"
            if notion_url:
                msg += f"   ğŸ”— [ë…¸ì…˜ì—ì„œ ë³´ê¸°]({notion_url})\n"

            # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ í‘œì‹œ (ë‚´ìš© ê²€ìƒ‰ì¸ ê²½ìš°)
            if result.get("search_context"):
                context = result["search_context"][:120]  # ê¸¸ì´ ì œí•œ ì¤„ì„
                msg += f"   ğŸ’¬ {context}\n"

            msg += "\n"

        # ë” ë§ì€ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        if total > 8:
            msg += f"... ê·¸ ì™¸ {total - 8}ê°œ ê²°ê³¼ ë” ìˆìŒ\n\n"

        # ê²€ìƒ‰ ì œì•ˆ ì¶”ê°€ (ê²°ê³¼ê°€ ìˆì–´ë„ í‘œì‹œ)
        if suggestions and total < 15:  # ê²°ê³¼ê°€ ì ì„ ë•Œë§Œ ì œì•ˆ í‘œì‹œ
            suggestion_parts = []

            if suggestions.get("related_keywords"):
                suggestion_parts.append(
                    f"ğŸ”— **ì—°ê´€**: {', '.join(suggestions['related_keywords'][:4])}"
                )

            if suggestions.get("popular_searches"):
                popular = [
                    s
                    for s in suggestions["popular_searches"][:3]
                    if s.lower() != query.lower()
                ]
                if popular:
                    suggestion_parts.append(f"ğŸ”¥ **ì¸ê¸°**: {', '.join(popular)}")

            if suggestion_parts:
                msg += "---\n" + " | ".join(suggestion_parts)

        return msg


# Global search service instance
search_service = SearchService()
